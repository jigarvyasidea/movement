# Movement

[![Python Version](https://img.shields.io/pypi/pyversions/movement.svg)](https://pypi.org/project/movement)
[![PyPI Version](https://img.shields.io/pypi/v/movement.svg)](https://pypi.org/project/movement)
[![Conda Forge Version](https://anaconda.org/conda-forge/movement/badges/version.svg)](https://anaconda.org/conda-forge/movement)
[![License](https://img.shields.io/badge/License-BSD_3--Clause-orange.svg)](https://opensource.org/licenses/BSD-3-Clause)
[![CI](https://img.shields.io/github/actions/workflow/status/neuroinformatics-unit/movement/test_and_deploy.yml?label=CI)](https://github.com/neuroinformatics-unit/movement/actions)
[![codecov](https://codecov.io/gh/neuroinformatics-unit/movement/branch/main/graph/badge.svg?token=P8CCH3TI8K)](https://codecov.io/gh/neuroinformatics-unit/movement)
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/neuroinformatics-unit/movement/gh-pages?filepath=notebooks/examples)
[![Code style: Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/format.json)](https://github.com/astral-sh/ruff)
[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![project chat](https://img.shields.io/badge/zulip-join_chat-brightgreen.svg)](https://neuroinformatics.zulipchat.com/#narrow/stream/406001-Movement/topic/Welcome!)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.12755724.svg)](https://zenodo.org/doi/10.5281/zenodo.12755724)

A Python toolbox for analyzing animal body movements across space and time.

![Movement Overview](docs/source/_static/movement_overview.png)

## üìã Table of Contents

- [Quick Install](#-quick-install)
- [Overview](#-overview)
- [Features](#-features)
- [Documentation](#-documentation)
- [Community](#-community)
- [Citation](#-citation)
- [License](#-license)

## üöÄ Quick Install

Create and activate a conda environment with movement installed (including the GUI):

```bash
conda create -n movement-env -c conda-forge movement napari pyqt
conda activate movement-env
```

> **Note:** For full installation instructions, please refer to our [detailed guide](https://movement.neuroinformatics.dev/user_guide/installation.html).

## üìù Overview

Deep learning methods for motion tracking have revolutionized a range of scientific disciplines, from neuroscience and biomechanics, to conservation and ethology. Tools such as [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and [SLEAP](https://sleap.ai/) now allow researchers to track animal movements in videos with remarkable accuracy, without requiring physical markers. However, there is still a need for standardized, easy-to-use methods to process the tracks generated by these tools.

`movement` aims to provide a consistent, modular interface for analyzing motion tracks, enabling steps such as:
- Data cleaning
- Visualization
- Motion quantification

We aim to support all popular animal tracking frameworks and file formats.

> **‚ö†Ô∏è Warning:** The package is currently in early development and the interface is subject to change. Feel free to play around and provide feedback.

## ‚ú® Features

- Standardized import of tracking data from popular formats
- Robust data cleaning and filtering algorithms
- Comprehensive visualization tools
- Quantitative analysis of movement patterns
- Graphical user interface powered by napari

> **üí° Tip:** If you prefer analyzing your data in R, we recommend checking out the [animovement](https://www.roald-arboel.com/animovement/) toolbox, which is similar in scope. We are working together with its developer to gradually converge on common data standards and workflows.

## üìö Documentation

For more information, check out our [comprehensive documentation](https://movement.neuroinformatics.dev), which includes:

- [Installation guide](https://movement.neuroinformatics.dev/user_guide/installation.html)
- [Tutorials and examples](https://movement.neuroinformatics.dev/examples/index.html)
- [API reference](https://movement.neuroinformatics.dev/api/index.html)
- [Mission and scope](https://movement.neuroinformatics.dev/community/mission-scope.html)
- [Project roadmap](https://movement.neuroinformatics.dev/community/roadmaps.html)

## üë• Community

Contributions to `movement` are absolutely encouraged, whether to fix a bug, develop a new feature, or improve the documentation. To help you get started, we have prepared a detailed [contributing guide](https://movement.neuroinformatics.dev/community/contributing.html).

Ways to get involved:
- [Chat with the team on Zulip](https://neuroinformatics.zulipchat.com/#narrow/stream/406001-Movement)
- [Open an issue](https://github.com/neuroinformatics-unit/movement/issues) to report a bug or request a new feature
- [Follow this Zulip topic](https://neuroinformatics.zulipchat.com/#narrow/channel/406001-Movement/topic/Community.20Calls) to receive updates about upcoming Community Calls

## üìÑ Citation

If you use movement in your work, please cite the following Zenodo DOI:

> Nikoloz Sirmpilatze, Chang Huan Lo, Sof√≠a Mi√±ano, Brandon D. Peri, Dhruv Sharma, Laura Porta, Iv√°n Varela & Adam L. Tyson (2024). neuroinformatics-unit/movement. Zenodo. https://zenodo.org/doi/10.5281/zenodo.12755724

## ‚öñÔ∏è License

[BSD 3-Clause](./LICENSE)

---

This package layout and configuration (including pre-commit hooks and GitHub actions) have been copied from the [python-cookiecutter](https://github.com/neuroinformatics-unit/python-cookiecutter) template.
